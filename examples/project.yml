title: "Adversarial Splitting Examples"
description: |
  This project shows different adversarial splitting examples
  in some machine learning datasets (most are NLP).

directories:
  - "assets"
  - "configs"
  - "corpus"
  - "scripts"

vars:
  train_dataset: corpus/en-wikineural-train.spacy
  dev_dataset: corpus/en-wikineural-dev.spacy
  test_dataset: corpus/en-wikineural-test.spacy
  config: configs/ner.cfg
  vectors: en_core_web_lg
  gpu_id: 0
  max_steps: 20000

assets:
  - dest: "assets/raw-en-wikineural-train.iob"
    description: "WikiNeural (en) training dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/en/train.conllu
  - dest: "assets/raw-en-wikineural-dev.iob"
    description: "WikiNeural (en) dev dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/en/val.conllu
  - dest: "assets/raw-en-wikineural-test.iob"
    description: "WikiNeural (en) test dataset from Tedeschi et al. (EMNLP 2021)"
    url: https://github.com/Babelscape/wikineural/blob/master/data/wikineural/en/test.conllu
  - dest: "assets/wnut17-train.iob"
    description: "WNUT17 training dataset for Emerging and Rare Entities Task from Derczynski et al., 2017"
    url: https://github.com/juand-r/entity-recognition-datasets/blob/master/data/WNUT17/CONLL-format/data/train/wnut17train.conll
  - dest: "assets/wnut17-dev.iob"
    description: "WNUT17 dev dataset for Emerging and Rare Entities Task from Derczynski et al., 2017"
    url: https://github.com/juand-r/entity-recognition-datasets/blob/master/data/WNUT17/CONLL-format/data/dev/emerging.dev.conll
  - dest: "assets/wnut17-test.iob"
    description: "WNUT17 test dataset for Emerging and Rare Entities Task from Derczynski et al., 2017"
    url: https://github.com/juand-r/entity-recognition-datasets/blob/master/data/WNUT17/CONLL-format/data/test/emerging.test.annotated

commands:
  - name: "convert-wikineural"
    help: "Convert Wikineural dataset into spaCy Docs"
    script:
      - >-
        python -m scripts.preprocess_wikineural 
        assets/raw-en-wikineural-train.iob assets/en-wikineural-train.iob
      - >-
        python -m scripts.preprocess_wikineural 
        assets/raw-en-wikineural-dev.iob assets/en-wikineural-dev.iob
      - >-
        python -m scripts.preprocess_wikineural 
        assets/raw-en-wikineural-test.iob assets/en-wikineural-test.iob
      - python -m spacy convert assets/en-wikineural-train.iob corpus/
      - python -m spacy convert assets/en-wikineural-dev.iob corpus/
      - python -m spacy convert assets/en-wikineural-test.iob corpus/
    deps:
      - assets/raw-en-wikineural-train.iob
      - assets/raw-en-wikineural-dev.iob
      - assets/raw-en-wikineural-test.iob
    outputs:
      - corpus/en-wikineural-train.spacy
      - corpus/en-wikineural-dev.spacy
      - corpus/en-wikineural-test.spacy

  - name: "convert-wnut17"
    help: "Convert WNUT17 into spaCy Docs"
    script:
      - python -m spacy convert assets/wnut17-train.iob corpus/
      - python -m spacy convert assets/wnut17-dev.iob corpus/
      - python -m spacy convert assets/wnut17-test.iob corpus/
    deps:
      - assets/wnut17-train.iob
      - assets/wnut17-dev.iob
      - assets/wnut17-test.iob
    outputs:
      - corpus/wnut-17-train.spacy
      - corpus/wnut-17-dev.spacy
      - corpus/wnut-17-test.spacy

  - name: "convert-conll2003"
    help: "Convert ConLL2003 into spaCy Docs (IOB files are shipped together with this project)"
    script:
      - python -m spacy convert assets/conll2003-train.iob corpus/
      - python -m spacy convert assets/conll2003-valid.iob corpus/
      - python -m spacy convert assets/conll2003-test.iob corpus/
    deps:
      - assets/conll2003-train.iob
      - assets/conll2003-valid.iob
      - assets/conll2003-test.iob
    outputs:
      - corpus/conll2003-train.spacy
      - corpus/conll2003-valid.spacy
      - corpus/conll2003-test.spacy

  - name: "demo"
    help: "Run the Divergence Maximization demo"
    script:
      - >-
        python3 -m scripts.run_demo ${vars.config} 
        --train-dataset ${vars.train_dataset}
        --dev-dataset ${vars.dev_dataset}
        --test-dataset ${vars.test_dataset}
        --vectors ${vars.vectors} 
        --use-gpu ${vars.gpu_id}
        --max-steps ${vars.max_steps}
        --base-model ${vars.vectors}
